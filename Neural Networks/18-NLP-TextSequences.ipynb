{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"18-NLP-TextSequences.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMsQK/+7UkdeGIgopaAV2HC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"jHA_N7011fd8","executionInfo":{"status":"ok","timestamp":1650724352103,"user_tz":300,"elapsed":6059,"user":{"displayName":"Shivali Dalmia","userId":"13522911372350483594"}}},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer"]},{"cell_type":"code","source":["sentences = [\n","    'i like my house',\n","    'I, like my car',\n","    'You like my car!',\n","    'Do you think my car is expensive?'\n","]\n","\n","tokenizer = Tokenizer(num_words = 100,oov_token=\"<OOV>\") #Out of vocabulary token \n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","\n","sequences = tokenizer.texts_to_sequences(sentences)\n","\n","print(\"\\nWord Index = \" , word_index)\n","print(\"\\nSequences = \" , sequences)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZ8KbPPu1oO1","executionInfo":{"status":"ok","timestamp":1650724734461,"user_tz":300,"elapsed":411,"user":{"displayName":"Shivali Dalmia","userId":"13522911372350483594"}},"outputId":"5cf6b890-9ab8-4a0e-8df8-8bf38e0fb543"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word Index =  {'<OOV>': 1, 'my': 2, 'like': 3, 'car': 4, 'i': 5, 'you': 6, 'house': 7, 'do': 8, 'think': 9, 'is': 10, 'expensive': 11}\n","\n","Sequences =  [[5, 3, 2, 7], [5, 3, 2, 4], [6, 3, 2, 4], [8, 6, 9, 2, 4, 10, 11]]\n"]}]},{"cell_type":"code","source":["# Try with words that the tokenizer wasn't fit to\n","test_data = [\n","    'i really like my house',\n","    'my friend likes my car'\n","]\n","\n","#How does it deal with new words which are not seen in train data set\n","# It has the skipped/ignoring the new word really (so 'i really like my house' same as 'i like my house')\n","test_seq = tokenizer.texts_to_sequences(test_data)\n","print(\"\\nTest Sequence = \", test_seq)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6c_0B-41uay","executionInfo":{"status":"ok","timestamp":1650724617675,"user_tz":300,"elapsed":244,"user":{"displayName":"Shivali Dalmia","userId":"13522911372350483594"}},"outputId":"ee6294df-4404-4765-b61d-6244bd2007fd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test Sequence =  [[4, 2, 1, 6], [1, 1, 3]]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"UMec93gw16Fb"},"execution_count":null,"outputs":[]}]}