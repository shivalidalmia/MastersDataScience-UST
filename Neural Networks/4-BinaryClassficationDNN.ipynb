{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4-BinaryClassficationDNN.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1qhlEfcYP5xbghGp9-bY_UtyMbPHKyh5T","authorship_tag":"ABX9TyPPevi9BjFkWf/j0kNITyYF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"c6UbsI5YV4nr","executionInfo":{"status":"ok","timestamp":1645299004253,"user_tz":360,"elapsed":73,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"outputs":[],"source":["# We will now be importing some required libraries\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"code","source":["#Loading the dataset\n","dataset = pd.read_csv('drive/My Drive/SEIS764/customers.csv')\n","\n","X = dataset.iloc[:,3:13].values\n","y = dataset.iloc[:,13].values"],"metadata":{"id":"-t82ZhomWNkW","executionInfo":{"status":"ok","timestamp":1645299004462,"user_tz":360,"elapsed":85,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Checking target and predicting features\n","print(X)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNSvemWZWUy2","executionInfo":{"status":"ok","timestamp":1645299004463,"user_tz":360,"elapsed":5,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}},"outputId":"6064f3f3-b506-408c-d6a3-430bf4ab0e7c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 'Female' ... 1 1 101348.88]\n"," [608 'Spain' 'Female' ... 0 1 112542.58]\n"," [502 'France' 'Female' ... 1 0 113931.57]\n"," ...\n"," [709 'France' 'Female' ... 0 1 42085.58]\n"," [772 'Germany' 'Male' ... 1 0 92888.52]\n"," [792 'France' 'Female' ... 1 0 38190.78]]\n","[1 0 1 ... 1 1 0]\n"]}]},{"cell_type":"code","source":["# Encoding categorical data\n","# Encoding the Independent Variable\n","\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","\n","#Label Encoding Gender\n","labelencoder_X = LabelEncoder()\n","X[:, 2] = labelencoder_X.fit_transform(X[:, 2])\n","\n","#Dealing with the categorical Geography column\n","from sklearn.compose import make_column_transformer\n","onehotencoder = make_column_transformer((OneHotEncoder(), [1]), remainder='passthrough')\n","X = onehotencoder.fit_transform(X)\n","\n","#Removing the extra dummy variable\n","X = X[:, 1:]"],"metadata":{"id":"fq_MEQzoWWuI","executionInfo":{"status":"ok","timestamp":1645299005407,"user_tz":360,"elapsed":947,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Splitting the data into Training Set and Test Set\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"],"metadata":{"id":"eXt1Guf9W7z2","executionInfo":{"status":"ok","timestamp":1645299005949,"user_tz":360,"elapsed":543,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Normalizing the features\n","from sklearn.preprocessing import StandardScaler\n","sc_X = StandardScaler()\n","X_train = sc_X.fit_transform(X_train)\n","X_test = sc_X.transform(X_test)"],"metadata":{"id":"G2T8KgmvXVjv","executionInfo":{"status":"ok","timestamp":1645299005950,"user_tz":360,"elapsed":25,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"JErIWI8BXjLN","executionInfo":{"status":"ok","timestamp":1645299011805,"user_tz":360,"elapsed":5875,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Define the model\n","model = tf.keras.models.Sequential()"],"metadata":{"id":"rTO5feNlXxrS","executionInfo":{"status":"ok","timestamp":1645299013288,"user_tz":360,"elapsed":1488,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Adding the first layer\n","model.add(tf.keras.layers.Dense(units=6, input_shape=[11],activation='relu'))\n","#model.add(tf.keras.layers.Dropout(0.1))\n","\n","#Adding a second hidden layer\n","model.add(tf.keras.layers.Dense(units=6, activation='relu'))\n","#model.add(tf.keras.layers.Dropout(0.1))\n","\n","#Adding an output layer\n","model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"],"metadata":{"id":"ZXQAEikxX81S","executionInfo":{"status":"ok","timestamp":1645299013516,"user_tz":360,"elapsed":230,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"R_EIP3aqYdxB","executionInfo":{"status":"ok","timestamp":1645299013518,"user_tz":360,"elapsed":7,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3T0g_Q0tYjwU","executionInfo":{"status":"ok","timestamp":1645299116641,"user_tz":360,"elapsed":102985,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}},"outputId":"9a695f78-6b57-484f-a1b1-10c8c6a26d28"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","250/250 [==============================] - 4s 8ms/step - loss: 0.6426 - accuracy: 0.7271 - val_loss: 0.5602 - val_accuracy: 0.7975\n","Epoch 2/100\n","250/250 [==============================] - 2s 6ms/step - loss: 0.5092 - accuracy: 0.7960 - val_loss: 0.4670 - val_accuracy: 0.7975\n","Epoch 3/100\n","250/250 [==============================] - 2s 8ms/step - loss: 0.4530 - accuracy: 0.7960 - val_loss: 0.4354 - val_accuracy: 0.7975\n","Epoch 4/100\n","250/250 [==============================] - 2s 7ms/step - loss: 0.4326 - accuracy: 0.7960 - val_loss: 0.4234 - val_accuracy: 0.7975\n","Epoch 5/100\n","250/250 [==============================] - 1s 5ms/step - loss: 0.4230 - accuracy: 0.7960 - val_loss: 0.4155 - val_accuracy: 0.7975\n","Epoch 6/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.4161 - accuracy: 0.7960 - val_loss: 0.4109 - val_accuracy: 0.7975\n","Epoch 7/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.4094 - accuracy: 0.7960 - val_loss: 0.4033 - val_accuracy: 0.7975\n","Epoch 8/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.4023 - accuracy: 0.7960 - val_loss: 0.3969 - val_accuracy: 0.7975\n","Epoch 9/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3952 - accuracy: 0.7960 - val_loss: 0.3915 - val_accuracy: 0.7975\n","Epoch 10/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3888 - accuracy: 0.8075 - val_loss: 0.3849 - val_accuracy: 0.8475\n","Epoch 11/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3830 - accuracy: 0.8416 - val_loss: 0.3784 - val_accuracy: 0.8505\n","Epoch 12/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3780 - accuracy: 0.8447 - val_loss: 0.3729 - val_accuracy: 0.8535\n","Epoch 13/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3738 - accuracy: 0.8510 - val_loss: 0.3692 - val_accuracy: 0.8545\n","Epoch 14/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3695 - accuracy: 0.8516 - val_loss: 0.3632 - val_accuracy: 0.8565\n","Epoch 15/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3648 - accuracy: 0.8535 - val_loss: 0.3596 - val_accuracy: 0.8570\n","Epoch 16/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3610 - accuracy: 0.8555 - val_loss: 0.3558 - val_accuracy: 0.8610\n","Epoch 17/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3588 - accuracy: 0.8575 - val_loss: 0.3544 - val_accuracy: 0.8615\n","Epoch 18/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3568 - accuracy: 0.8575 - val_loss: 0.3529 - val_accuracy: 0.8600\n","Epoch 19/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3553 - accuracy: 0.8591 - val_loss: 0.3501 - val_accuracy: 0.8595\n","Epoch 20/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3543 - accuracy: 0.8583 - val_loss: 0.3486 - val_accuracy: 0.8620\n","Epoch 21/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3538 - accuracy: 0.8581 - val_loss: 0.3484 - val_accuracy: 0.8610\n","Epoch 22/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3529 - accuracy: 0.8586 - val_loss: 0.3468 - val_accuracy: 0.8615\n","Epoch 23/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3517 - accuracy: 0.8581 - val_loss: 0.3480 - val_accuracy: 0.8595\n","Epoch 24/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3512 - accuracy: 0.8601 - val_loss: 0.3475 - val_accuracy: 0.8585\n","Epoch 25/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3504 - accuracy: 0.8596 - val_loss: 0.3460 - val_accuracy: 0.8590\n","Epoch 26/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3499 - accuracy: 0.8609 - val_loss: 0.3456 - val_accuracy: 0.8590\n","Epoch 27/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3492 - accuracy: 0.8596 - val_loss: 0.3447 - val_accuracy: 0.8590\n","Epoch 28/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3486 - accuracy: 0.8610 - val_loss: 0.3447 - val_accuracy: 0.8590\n","Epoch 29/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3480 - accuracy: 0.8586 - val_loss: 0.3430 - val_accuracy: 0.8595\n","Epoch 30/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.8604 - val_loss: 0.3430 - val_accuracy: 0.8600\n","Epoch 31/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3473 - accuracy: 0.8608 - val_loss: 0.3429 - val_accuracy: 0.8605\n","Epoch 32/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3469 - accuracy: 0.8596 - val_loss: 0.3438 - val_accuracy: 0.8585\n","Epoch 33/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3461 - accuracy: 0.8610 - val_loss: 0.3449 - val_accuracy: 0.8595\n","Epoch 34/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3464 - accuracy: 0.8600 - val_loss: 0.3430 - val_accuracy: 0.8570\n","Epoch 35/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3456 - accuracy: 0.8621 - val_loss: 0.3419 - val_accuracy: 0.8595\n","Epoch 36/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3451 - accuracy: 0.8608 - val_loss: 0.3426 - val_accuracy: 0.8575\n","Epoch 37/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3445 - accuracy: 0.8611 - val_loss: 0.3415 - val_accuracy: 0.8570\n","Epoch 38/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3443 - accuracy: 0.8616 - val_loss: 0.3407 - val_accuracy: 0.8595\n","Epoch 39/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3442 - accuracy: 0.8612 - val_loss: 0.3402 - val_accuracy: 0.8585\n","Epoch 40/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3439 - accuracy: 0.8608 - val_loss: 0.3400 - val_accuracy: 0.8590\n","Epoch 41/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3433 - accuracy: 0.8614 - val_loss: 0.3396 - val_accuracy: 0.8585\n","Epoch 42/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3431 - accuracy: 0.8611 - val_loss: 0.3409 - val_accuracy: 0.8615\n","Epoch 43/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3429 - accuracy: 0.8604 - val_loss: 0.3393 - val_accuracy: 0.8570\n","Epoch 44/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3426 - accuracy: 0.8614 - val_loss: 0.3393 - val_accuracy: 0.8590\n","Epoch 45/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3425 - accuracy: 0.8616 - val_loss: 0.3391 - val_accuracy: 0.8570\n","Epoch 46/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.8615 - val_loss: 0.3395 - val_accuracy: 0.8575\n","Epoch 47/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3420 - accuracy: 0.8616 - val_loss: 0.3385 - val_accuracy: 0.8620\n","Epoch 48/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3415 - accuracy: 0.8614 - val_loss: 0.3391 - val_accuracy: 0.8590\n","Epoch 49/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.8610 - val_loss: 0.3400 - val_accuracy: 0.8595\n","Epoch 50/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3412 - accuracy: 0.8612 - val_loss: 0.3400 - val_accuracy: 0.8625\n","Epoch 51/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3411 - accuracy: 0.8612 - val_loss: 0.3384 - val_accuracy: 0.8600\n","Epoch 52/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3410 - accuracy: 0.8616 - val_loss: 0.3390 - val_accuracy: 0.8580\n","Epoch 53/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3405 - accuracy: 0.8616 - val_loss: 0.3390 - val_accuracy: 0.8590\n","Epoch 54/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3404 - accuracy: 0.8620 - val_loss: 0.3394 - val_accuracy: 0.8585\n","Epoch 55/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3402 - accuracy: 0.8614 - val_loss: 0.3396 - val_accuracy: 0.8610\n","Epoch 56/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3399 - accuracy: 0.8604 - val_loss: 0.3390 - val_accuracy: 0.8595\n","Epoch 57/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3397 - accuracy: 0.8616 - val_loss: 0.3372 - val_accuracy: 0.8590\n","Epoch 58/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3397 - accuracy: 0.8621 - val_loss: 0.3397 - val_accuracy: 0.8605\n","Epoch 59/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8612 - val_loss: 0.3379 - val_accuracy: 0.8605\n","Epoch 60/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8625 - val_loss: 0.3387 - val_accuracy: 0.8575\n","Epoch 61/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3390 - accuracy: 0.8621 - val_loss: 0.3397 - val_accuracy: 0.8595\n","Epoch 62/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3389 - accuracy: 0.8619 - val_loss: 0.3383 - val_accuracy: 0.8605\n","Epoch 63/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3387 - accuracy: 0.8611 - val_loss: 0.3377 - val_accuracy: 0.8595\n","Epoch 64/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3388 - accuracy: 0.8612 - val_loss: 0.3385 - val_accuracy: 0.8605\n","Epoch 65/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3387 - accuracy: 0.8625 - val_loss: 0.3390 - val_accuracy: 0.8620\n","Epoch 66/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.8616 - val_loss: 0.3383 - val_accuracy: 0.8595\n","Epoch 67/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.8629 - val_loss: 0.3381 - val_accuracy: 0.8610\n","Epoch 68/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3380 - accuracy: 0.8631 - val_loss: 0.3373 - val_accuracy: 0.8620\n","Epoch 69/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3381 - accuracy: 0.8614 - val_loss: 0.3388 - val_accuracy: 0.8610\n","Epoch 70/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3381 - accuracy: 0.8611 - val_loss: 0.3377 - val_accuracy: 0.8600\n","Epoch 71/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3378 - accuracy: 0.8610 - val_loss: 0.3377 - val_accuracy: 0.8625\n","Epoch 72/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3378 - accuracy: 0.8610 - val_loss: 0.3372 - val_accuracy: 0.8600\n","Epoch 73/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3377 - accuracy: 0.8606 - val_loss: 0.3377 - val_accuracy: 0.8625\n","Epoch 74/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.8610 - val_loss: 0.3379 - val_accuracy: 0.8600\n","Epoch 75/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3372 - accuracy: 0.8620 - val_loss: 0.3380 - val_accuracy: 0.8605\n","Epoch 76/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3371 - accuracy: 0.8618 - val_loss: 0.3383 - val_accuracy: 0.8605\n","Epoch 77/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.8606 - val_loss: 0.3374 - val_accuracy: 0.8615\n","Epoch 78/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3373 - accuracy: 0.8619 - val_loss: 0.3371 - val_accuracy: 0.8600\n","Epoch 79/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3368 - accuracy: 0.8615 - val_loss: 0.3400 - val_accuracy: 0.8605\n","Epoch 80/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3367 - accuracy: 0.8611 - val_loss: 0.3390 - val_accuracy: 0.8625\n","Epoch 81/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3367 - accuracy: 0.8626 - val_loss: 0.3383 - val_accuracy: 0.8595\n","Epoch 82/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3363 - accuracy: 0.8619 - val_loss: 0.3416 - val_accuracy: 0.8595\n","Epoch 83/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3364 - accuracy: 0.8620 - val_loss: 0.3392 - val_accuracy: 0.8630\n","Epoch 84/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3364 - accuracy: 0.8610 - val_loss: 0.3396 - val_accuracy: 0.8620\n","Epoch 85/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8625 - val_loss: 0.3381 - val_accuracy: 0.8610\n","Epoch 86/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8622 - val_loss: 0.3386 - val_accuracy: 0.8615\n","Epoch 87/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3365 - accuracy: 0.8610 - val_loss: 0.3373 - val_accuracy: 0.8605\n","Epoch 88/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8611 - val_loss: 0.3382 - val_accuracy: 0.8620\n","Epoch 89/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3364 - accuracy: 0.8611 - val_loss: 0.3386 - val_accuracy: 0.8615\n","Epoch 90/100\n","250/250 [==============================] - 1s 6ms/step - loss: 0.3361 - accuracy: 0.8614 - val_loss: 0.3384 - val_accuracy: 0.8620\n","Epoch 91/100\n","250/250 [==============================] - 1s 6ms/step - loss: 0.3360 - accuracy: 0.8625 - val_loss: 0.3387 - val_accuracy: 0.8610\n","Epoch 92/100\n","250/250 [==============================] - 1s 6ms/step - loss: 0.3361 - accuracy: 0.8601 - val_loss: 0.3390 - val_accuracy: 0.8620\n","Epoch 93/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3357 - accuracy: 0.8614 - val_loss: 0.3380 - val_accuracy: 0.8605\n","Epoch 94/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3355 - accuracy: 0.8611 - val_loss: 0.3385 - val_accuracy: 0.8590\n","Epoch 95/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8611 - val_loss: 0.3395 - val_accuracy: 0.8605\n","Epoch 96/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3353 - accuracy: 0.8626 - val_loss: 0.3392 - val_accuracy: 0.8610\n","Epoch 97/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8612 - val_loss: 0.3380 - val_accuracy: 0.8590\n","Epoch 98/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3353 - accuracy: 0.8622 - val_loss: 0.3372 - val_accuracy: 0.8580\n","Epoch 99/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3354 - accuracy: 0.8620 - val_loss: 0.3385 - val_accuracy: 0.8610\n","Epoch 100/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3354 - accuracy: 0.8624 - val_loss: 0.3378 - val_accuracy: 0.8590\n"]}]},{"cell_type":"code","source":["# Evaluate the model, prints loss and accuracy\n","print(\"Train score:\", model.evaluate(X_train, y_train))\n","print(\"Test score:\", model.evaluate(X_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvbhv8Q_YoHT","executionInfo":{"status":"ok","timestamp":1645299118334,"user_tz":360,"elapsed":1707,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}},"outputId":"c49be55d-7af7-4628-9ad9-79f27a8f1896"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["250/250 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8621\n","Train score: [0.33324846625328064, 0.8621249794960022]\n","63/63 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8590\n","Test score: [0.3377910554409027, 0.859000027179718]\n"]}]},{"cell_type":"code","source":["# Plot the loss\n","import matplotlib.pyplot as plt\n","plt.plot(r.history['loss'], label='loss')\n","plt.plot(r.history['val_loss'], label='val_loss')\n","plt.legend()\n","plt.show()\n","\n","# Plot the accuracy \n","plt.plot(r.history['accuracy'], label='acc')\n","plt.plot(r.history['val_accuracy'], label='val_acc')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"1TE_v504ZKsR","executionInfo":{"status":"ok","timestamp":1645299118804,"user_tz":360,"elapsed":391,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}},"outputId":"05c1ac72-42ed-41e2-969b-9cfe6438562b"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["!pip install scikeras[tensorflow]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_Ay7E1UZP7_","executionInfo":{"status":"ok","timestamp":1645299122254,"user_tz":360,"elapsed":3455,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}},"outputId":"ee6ec803-9e97-4c68-90e7-122aa56465ee"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikeras[tensorflow] in /usr/local/lib/python3.7/dist-packages (0.6.1)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (1.0.2)\n","Requirement already satisfied: packaging<22.0,>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (21.3)\n","Requirement already satisfied: importlib-metadata<4,>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (3.10.1)\n","Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (2.8.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4,>=3->scikeras[tensorflow]) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4,>=3->scikeras[tensorflow]) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22.0,>=0.21->scikeras[tensorflow]) (3.0.7)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.1.0)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.21.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.4.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.13.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.3.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.0.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.2.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.24.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.5.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.6.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.43.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0.dev2021122109)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (13.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (57.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.17.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.1.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.1.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.7.0->scikeras[tensorflow]) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->scikeras[tensorflow]) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.3.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.6.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.35.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.2.0)\n"]}]},{"cell_type":"code","source":["#Evaluating our Neural Network\n","from scikeras.wrappers import KerasClassifier\n","from sklearn.model_selection import cross_val_score"],"metadata":{"id":"jbTzdzBFZa10","executionInfo":{"status":"ok","timestamp":1645299163602,"user_tz":360,"elapsed":69,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def buildNN():\n","    # Define the model\n","    model = tf.keras.models.Sequential()\n","\n","    #Adding a first hidden layer\n","    model.add(tf.keras.layers.Dense(units=6, input_shape=[11], activation='relu'))\n","    #model.add(tf.keras.layers.Dropout(0.1))\n","\n","    #Adding a second hidden layer\n","    model.add(tf.keras.layers.Dense(units=6, activation='relu'))\n","    #model.add(tf.keras.layers.Dropout(0.1))\n","\n","    #Adding an output layer\n","    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n","\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    \n","    return model"],"metadata":{"id":"bL74G38geODj","executionInfo":{"status":"ok","timestamp":1645299177030,"user_tz":360,"elapsed":83,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["classifier = KerasClassifier(model = buildNN, batch_size=10, epochs=100)\n","accuracy = cross_val_score(estimator = classifier, X = X_train, y=y_train, cv=10,verbose=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yLOm-5LneRUT","executionInfo":{"status":"error","timestamp":1645301497235,"user_tz":360,"elapsed":1557096,"user":{"displayName":"Shivali Dalmia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiW9VNEBFZ8QSYDaIjXrruLmT7cKvBlGsevxDqvtw=s64","userId":"13522911372350483594"}},"outputId":"8a99ae98-9fa0-4bbe-98ee-4a8ac8ef0d4f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","720/720 [==============================] - 5s 6ms/step - loss: 0.5099 - accuracy: 0.7960\n","Epoch 2/100\n","720/720 [==============================] - 4s 5ms/step - loss: 0.4515 - accuracy: 0.7960\n","Epoch 3/100\n","720/720 [==============================] - 3s 5ms/step - loss: 0.4365 - accuracy: 0.7960\n","Epoch 4/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4291 - accuracy: 0.7960\n","Epoch 5/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4239 - accuracy: 0.7990\n","Epoch 6/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4189 - accuracy: 0.8107\n","Epoch 7/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4140 - accuracy: 0.8129\n","Epoch 8/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4092 - accuracy: 0.8171\n","Epoch 9/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4049 - accuracy: 0.8286\n","Epoch 10/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3988 - accuracy: 0.8319\n","Epoch 11/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3903 - accuracy: 0.8328\n","Epoch 12/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3811 - accuracy: 0.8392\n","Epoch 13/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3724 - accuracy: 0.8449\n","Epoch 14/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3647 - accuracy: 0.8512\n","Epoch 15/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3596 - accuracy: 0.8546\n","Epoch 16/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3554 - accuracy: 0.8571\n","Epoch 17/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3527 - accuracy: 0.8604\n","Epoch 18/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3509 - accuracy: 0.8619\n","Epoch 19/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3500 - accuracy: 0.8606\n","Epoch 20/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3494 - accuracy: 0.8612\n","Epoch 21/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3485 - accuracy: 0.8611\n","Epoch 22/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3484 - accuracy: 0.8608\n","Epoch 23/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3474 - accuracy: 0.8612\n","Epoch 24/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3470 - accuracy: 0.8607\n","Epoch 25/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3468 - accuracy: 0.8618\n","Epoch 26/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3460 - accuracy: 0.8604\n","Epoch 27/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3455 - accuracy: 0.8612\n","Epoch 28/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3453 - accuracy: 0.8635\n","Epoch 29/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3444 - accuracy: 0.8625\n","Epoch 30/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3444 - accuracy: 0.8622\n","Epoch 31/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3432 - accuracy: 0.8614\n","Epoch 32/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3437 - accuracy: 0.8629\n","Epoch 33/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3436 - accuracy: 0.8626\n","Epoch 34/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3429 - accuracy: 0.8631\n","Epoch 35/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3428 - accuracy: 0.8621\n","Epoch 36/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3418 - accuracy: 0.8624\n","Epoch 37/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3421 - accuracy: 0.8604\n","Epoch 38/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3416 - accuracy: 0.8611\n","Epoch 39/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3415 - accuracy: 0.8639\n","Epoch 40/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3406 - accuracy: 0.8626\n","Epoch 41/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3402 - accuracy: 0.8619\n","Epoch 42/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3392 - accuracy: 0.8619\n","Epoch 43/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3382 - accuracy: 0.8646\n","Epoch 44/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3387 - accuracy: 0.8633\n","Epoch 45/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3376 - accuracy: 0.8642\n","Epoch 46/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3367 - accuracy: 0.8636\n","Epoch 47/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3363 - accuracy: 0.8632\n","Epoch 48/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3362 - accuracy: 0.8622\n","Epoch 49/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3361 - accuracy: 0.8611\n","Epoch 50/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3359 - accuracy: 0.8631\n","Epoch 51/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3360 - accuracy: 0.8618\n","Epoch 52/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3353 - accuracy: 0.8637\n","Epoch 53/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3352 - accuracy: 0.8632\n","Epoch 54/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3348 - accuracy: 0.8635\n","Epoch 55/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3350 - accuracy: 0.8625\n","Epoch 56/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3350 - accuracy: 0.8622\n","Epoch 57/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3348 - accuracy: 0.8617\n","Epoch 58/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3352 - accuracy: 0.8624\n","Epoch 59/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3348 - accuracy: 0.8629\n","Epoch 60/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3348 - accuracy: 0.8622\n","Epoch 61/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3341 - accuracy: 0.8621\n","Epoch 62/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3344 - accuracy: 0.8632\n","Epoch 63/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3344 - accuracy: 0.8629\n","Epoch 64/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3343 - accuracy: 0.8628\n","Epoch 65/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3342 - accuracy: 0.8618\n","Epoch 66/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3342 - accuracy: 0.8626\n","Epoch 67/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3338 - accuracy: 0.8619\n","Epoch 68/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3342 - accuracy: 0.8617\n","Epoch 69/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3341 - accuracy: 0.8631\n","Epoch 70/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3339 - accuracy: 0.8637\n","Epoch 71/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3337 - accuracy: 0.8626\n","Epoch 72/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3340 - accuracy: 0.8637\n","Epoch 73/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3336 - accuracy: 0.8629\n","Epoch 74/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3334 - accuracy: 0.8625\n","Epoch 75/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3333 - accuracy: 0.8661\n","Epoch 76/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3334 - accuracy: 0.8625\n","Epoch 77/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3334 - accuracy: 0.8633\n","Epoch 78/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3332 - accuracy: 0.8632\n","Epoch 79/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3332 - accuracy: 0.8647\n","Epoch 80/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3318 - accuracy: 0.8637\n","Epoch 81/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3325 - accuracy: 0.8631\n","Epoch 82/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8633\n","Epoch 83/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3323 - accuracy: 0.8635\n","Epoch 84/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8629\n","Epoch 85/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3321 - accuracy: 0.8635\n","Epoch 86/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3318 - accuracy: 0.8632\n","Epoch 87/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3324 - accuracy: 0.8642\n","Epoch 88/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3316 - accuracy: 0.8628\n","Epoch 89/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3315 - accuracy: 0.8629\n","Epoch 90/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3315 - accuracy: 0.8625\n","Epoch 91/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3312 - accuracy: 0.8636\n","Epoch 92/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3309 - accuracy: 0.8647\n","Epoch 93/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3312 - accuracy: 0.8622\n","Epoch 94/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3310 - accuracy: 0.8650\n","Epoch 95/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3308 - accuracy: 0.8650\n","Epoch 96/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3310 - accuracy: 0.8633\n","Epoch 97/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3304 - accuracy: 0.8651\n","Epoch 98/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3294 - accuracy: 0.8660\n","Epoch 99/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3302 - accuracy: 0.8629\n","Epoch 100/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3305 - accuracy: 0.8649\n","80/80 [==============================] - 0s 2ms/step\n","[CV] END ................................ score: (test=0.858) total time= 4.4min\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.4min remaining:    0.0s\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","720/720 [==============================] - 3s 3ms/step - loss: 0.5290 - accuracy: 0.7739\n","Epoch 2/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4597 - accuracy: 0.7958\n","Epoch 3/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4257 - accuracy: 0.8090\n","Epoch 4/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4080 - accuracy: 0.8250\n","Epoch 5/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3999 - accuracy: 0.8296\n","Epoch 6/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3939 - accuracy: 0.8296\n","Epoch 7/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3881 - accuracy: 0.8328\n","Epoch 8/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3848 - accuracy: 0.8315\n","Epoch 9/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3809 - accuracy: 0.8381\n","Epoch 10/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3769 - accuracy: 0.8440\n","Epoch 11/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3729 - accuracy: 0.8483\n","Epoch 12/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3695 - accuracy: 0.8489\n","Epoch 13/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3660 - accuracy: 0.8517\n","Epoch 14/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3622 - accuracy: 0.8519\n","Epoch 15/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3590 - accuracy: 0.8528\n","Epoch 16/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3560 - accuracy: 0.8544\n","Epoch 17/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3533 - accuracy: 0.8558\n","Epoch 18/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3517 - accuracy: 0.8542\n","Epoch 19/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3505 - accuracy: 0.8554\n","Epoch 20/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3481 - accuracy: 0.8565\n","Epoch 21/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3482 - accuracy: 0.8585\n","Epoch 22/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3467 - accuracy: 0.8576\n","Epoch 23/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3457 - accuracy: 0.8583\n","Epoch 24/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3459 - accuracy: 0.8576\n","Epoch 25/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3446 - accuracy: 0.8615\n","Epoch 26/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3436 - accuracy: 0.8593\n","Epoch 27/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3434 - accuracy: 0.8606\n","Epoch 28/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3434 - accuracy: 0.8581\n","Epoch 29/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3422 - accuracy: 0.8607\n","Epoch 30/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3425 - accuracy: 0.8593\n","Epoch 31/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3424 - accuracy: 0.8606\n","Epoch 32/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3413 - accuracy: 0.8594\n","Epoch 33/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3413 - accuracy: 0.8587\n","Epoch 34/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3412 - accuracy: 0.8617\n","Epoch 35/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3405 - accuracy: 0.8607\n","Epoch 36/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3403 - accuracy: 0.8600\n","Epoch 37/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3395 - accuracy: 0.8612\n","Epoch 38/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3389 - accuracy: 0.8624\n","Epoch 39/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3389 - accuracy: 0.8611\n","Epoch 40/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3389 - accuracy: 0.8618\n","Epoch 41/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3382 - accuracy: 0.8628\n","Epoch 42/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3380 - accuracy: 0.8619\n","Epoch 43/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3385 - accuracy: 0.8618\n","Epoch 44/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3378 - accuracy: 0.8631\n","Epoch 45/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3374 - accuracy: 0.8629\n","Epoch 46/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3368 - accuracy: 0.8618\n","Epoch 47/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3366 - accuracy: 0.8631\n","Epoch 48/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3373 - accuracy: 0.8615\n","Epoch 49/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3363 - accuracy: 0.8642\n","Epoch 50/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3363 - accuracy: 0.8647\n","Epoch 51/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3363 - accuracy: 0.8646\n","Epoch 52/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3355 - accuracy: 0.8644\n","Epoch 53/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3361 - accuracy: 0.8621\n","Epoch 54/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3351 - accuracy: 0.8642\n","Epoch 55/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3351 - accuracy: 0.8658\n","Epoch 56/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3358 - accuracy: 0.8628\n","Epoch 57/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3348 - accuracy: 0.8665\n","Epoch 58/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3353 - accuracy: 0.8647\n","Epoch 59/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3349 - accuracy: 0.8636\n","Epoch 60/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3351 - accuracy: 0.8637\n","Epoch 61/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3344 - accuracy: 0.8639\n","Epoch 62/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3346 - accuracy: 0.8644\n","Epoch 63/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3345 - accuracy: 0.8637\n","Epoch 64/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3340 - accuracy: 0.8649\n","Epoch 65/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3343 - accuracy: 0.8656\n","Epoch 66/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3347 - accuracy: 0.8657\n","Epoch 67/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3336 - accuracy: 0.8665\n","Epoch 68/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3343 - accuracy: 0.8661\n","Epoch 69/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3331 - accuracy: 0.8657\n","Epoch 70/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3342 - accuracy: 0.8650\n","Epoch 71/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3333 - accuracy: 0.8667\n","Epoch 72/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3338 - accuracy: 0.8640\n","Epoch 73/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3333 - accuracy: 0.8654\n","Epoch 74/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3339 - accuracy: 0.8632\n","Epoch 75/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3338 - accuracy: 0.8650\n","Epoch 76/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3337 - accuracy: 0.8643\n","Epoch 77/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3326 - accuracy: 0.8661\n","Epoch 78/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3333 - accuracy: 0.8647\n","Epoch 79/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3322 - accuracy: 0.8658\n","Epoch 80/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3334 - accuracy: 0.8657\n","Epoch 81/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3335 - accuracy: 0.8649\n","Epoch 82/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3330 - accuracy: 0.8654\n","Epoch 83/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3329 - accuracy: 0.8643\n","Epoch 84/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8647\n","Epoch 85/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3333 - accuracy: 0.8646\n","Epoch 86/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3335 - accuracy: 0.8635\n","Epoch 87/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3330 - accuracy: 0.8646\n","Epoch 88/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3329 - accuracy: 0.8635\n","Epoch 89/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3333 - accuracy: 0.8644\n","Epoch 90/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3327 - accuracy: 0.8657\n","Epoch 91/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3331 - accuracy: 0.8651\n","Epoch 92/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3329 - accuracy: 0.8642\n","Epoch 93/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3326 - accuracy: 0.8650\n","Epoch 94/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3326 - accuracy: 0.8675\n","Epoch 95/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3323 - accuracy: 0.8643\n","Epoch 96/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3326 - accuracy: 0.8625\n","Epoch 97/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3327 - accuracy: 0.8651\n","Epoch 98/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8647\n","Epoch 99/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3322 - accuracy: 0.8628\n","Epoch 100/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8662\n","80/80 [==============================] - 0s 2ms/step\n","[CV] END ................................ score: (test=0.855) total time= 3.7min\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  8.1min remaining:    0.0s\n"]},{"output_type":"stream","name":"stdout","text":["720/720 [==============================] - 3s 3ms/step - loss: 0.5468 - accuracy: 0.7499\n","Epoch 2/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4310 - accuracy: 0.8060\n","Epoch 3/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4045 - accuracy: 0.8149\n","Epoch 4/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3905 - accuracy: 0.8172\n","Epoch 5/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3827 - accuracy: 0.8179\n","Epoch 6/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3776 - accuracy: 0.8190\n","Epoch 7/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3738 - accuracy: 0.8196\n","Epoch 8/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3711 - accuracy: 0.8194\n","Epoch 9/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3688 - accuracy: 0.8388\n","Epoch 10/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3671 - accuracy: 0.8479\n","Epoch 11/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3652 - accuracy: 0.8506\n","Epoch 12/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3641 - accuracy: 0.8494\n","Epoch 13/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3626 - accuracy: 0.8512\n","Epoch 14/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3617 - accuracy: 0.8531\n","Epoch 15/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3601 - accuracy: 0.8532\n","Epoch 16/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3590 - accuracy: 0.8518\n","Epoch 17/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3585 - accuracy: 0.8543\n","Epoch 18/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3571 - accuracy: 0.8529\n","Epoch 19/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3564 - accuracy: 0.8533\n","Epoch 20/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3554 - accuracy: 0.8544\n","Epoch 21/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3545 - accuracy: 0.8568\n","Epoch 22/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3537 - accuracy: 0.8557\n","Epoch 23/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3526 - accuracy: 0.8593\n","Epoch 24/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3522 - accuracy: 0.8564\n","Epoch 25/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3506 - accuracy: 0.8574\n","Epoch 26/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3476 - accuracy: 0.8578\n","Epoch 27/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3451 - accuracy: 0.8603\n","Epoch 28/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3441 - accuracy: 0.8556\n","Epoch 29/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3435 - accuracy: 0.8579\n","Epoch 30/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3431 - accuracy: 0.8575\n","Epoch 31/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3422 - accuracy: 0.8585\n","Epoch 32/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3419 - accuracy: 0.8581\n","Epoch 33/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3412 - accuracy: 0.8565\n","Epoch 34/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3407 - accuracy: 0.8608\n","Epoch 35/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3411 - accuracy: 0.8579\n","Epoch 36/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3407 - accuracy: 0.8568\n","Epoch 37/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3402 - accuracy: 0.8582\n","Epoch 38/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3402 - accuracy: 0.8593\n","Epoch 39/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3390 - accuracy: 0.8608\n","Epoch 40/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3400 - accuracy: 0.8604\n","Epoch 41/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3397 - accuracy: 0.8592\n","Epoch 42/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3394 - accuracy: 0.8589\n","Epoch 43/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3389 - accuracy: 0.8608\n","Epoch 44/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3390 - accuracy: 0.8594\n","Epoch 45/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3389 - accuracy: 0.8604\n","Epoch 46/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3384 - accuracy: 0.8583\n","Epoch 47/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3387 - accuracy: 0.8610\n","Epoch 48/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3388 - accuracy: 0.8614\n","Epoch 49/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3389 - accuracy: 0.8594\n","Epoch 50/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3384 - accuracy: 0.8615\n","Epoch 51/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3389 - accuracy: 0.8572\n","Epoch 52/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3385 - accuracy: 0.8617\n","Epoch 53/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3382 - accuracy: 0.8610\n","Epoch 54/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3384 - accuracy: 0.8617\n","Epoch 55/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3384 - accuracy: 0.8624\n","Epoch 56/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3375 - accuracy: 0.8611\n","Epoch 57/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3380 - accuracy: 0.8612\n","Epoch 58/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3375 - accuracy: 0.8615\n","Epoch 59/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3377 - accuracy: 0.8633\n","Epoch 60/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3383 - accuracy: 0.8606\n","Epoch 61/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3377 - accuracy: 0.8618\n","Epoch 62/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3372 - accuracy: 0.8617\n","Epoch 63/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3382 - accuracy: 0.8614\n","Epoch 64/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3375 - accuracy: 0.8612\n","Epoch 65/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3377 - accuracy: 0.8622\n","Epoch 66/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3375 - accuracy: 0.8625\n","Epoch 67/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3373 - accuracy: 0.8614\n","Epoch 68/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3373 - accuracy: 0.8614\n","Epoch 69/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3372 - accuracy: 0.8622\n","Epoch 70/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3377 - accuracy: 0.8621\n","Epoch 71/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3371 - accuracy: 0.8629\n","Epoch 72/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3372 - accuracy: 0.8635\n","Epoch 73/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3369 - accuracy: 0.8631\n","Epoch 74/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3372 - accuracy: 0.8631\n","Epoch 75/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3374 - accuracy: 0.8614\n","Epoch 76/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3372 - accuracy: 0.8629\n","Epoch 77/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3375 - accuracy: 0.8619\n","Epoch 78/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3369 - accuracy: 0.8626\n","Epoch 79/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3373 - accuracy: 0.8615\n","Epoch 80/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3370 - accuracy: 0.8617\n","Epoch 81/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3364 - accuracy: 0.8640\n","Epoch 82/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3370 - accuracy: 0.8632\n","Epoch 83/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3369 - accuracy: 0.8632\n","Epoch 84/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3368 - accuracy: 0.8610\n","Epoch 85/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3370 - accuracy: 0.8617\n","Epoch 86/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3361 - accuracy: 0.8633\n","Epoch 87/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3362 - accuracy: 0.8629\n","Epoch 88/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3367 - accuracy: 0.8637\n","Epoch 89/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3364 - accuracy: 0.8642\n","Epoch 90/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3364 - accuracy: 0.8629\n","Epoch 91/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3363 - accuracy: 0.8653\n","Epoch 92/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3365 - accuracy: 0.8647\n","Epoch 93/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3365 - accuracy: 0.8622\n","Epoch 94/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3364 - accuracy: 0.8640\n","Epoch 95/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3364 - accuracy: 0.8624\n","Epoch 96/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3359 - accuracy: 0.8644\n","Epoch 97/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3359 - accuracy: 0.8612\n","Epoch 98/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3367 - accuracy: 0.8629\n","Epoch 99/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3356 - accuracy: 0.8636\n","Epoch 100/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3368 - accuracy: 0.8637\n","80/80 [==============================] - 0s 2ms/step\n","[CV] END ................................ score: (test=0.879) total time= 4.4min\n","Epoch 1/100\n","720/720 [==============================] - 3s 3ms/step - loss: 0.5038 - accuracy: 0.7900\n","Epoch 2/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4183 - accuracy: 0.8128\n","Epoch 3/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3832 - accuracy: 0.8332\n","Epoch 4/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3677 - accuracy: 0.8482\n","Epoch 5/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3587 - accuracy: 0.8524\n","Epoch 6/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3539 - accuracy: 0.8517\n","Epoch 7/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3510 - accuracy: 0.8547\n","Epoch 8/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3486 - accuracy: 0.8568\n","Epoch 9/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3463 - accuracy: 0.8583\n","Epoch 10/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3450 - accuracy: 0.8596\n","Epoch 11/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3438 - accuracy: 0.8622\n","Epoch 12/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3420 - accuracy: 0.8610\n","Epoch 13/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3414 - accuracy: 0.8593\n","Epoch 14/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3400 - accuracy: 0.8592\n","Epoch 15/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3397 - accuracy: 0.8611\n","Epoch 16/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3388 - accuracy: 0.8619\n","Epoch 17/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3387 - accuracy: 0.8597\n","Epoch 18/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3378 - accuracy: 0.8587\n","Epoch 19/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3372 - accuracy: 0.8597\n","Epoch 20/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3372 - accuracy: 0.8610\n","Epoch 21/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3367 - accuracy: 0.8600\n","Epoch 22/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3365 - accuracy: 0.8619\n","Epoch 23/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3359 - accuracy: 0.8621\n","Epoch 24/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3349 - accuracy: 0.8619\n","Epoch 25/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3354 - accuracy: 0.8607\n","Epoch 26/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3348 - accuracy: 0.8639\n","Epoch 27/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3343 - accuracy: 0.8632\n","Epoch 28/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3336 - accuracy: 0.8639\n","Epoch 29/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3339 - accuracy: 0.8626\n","Epoch 30/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3338 - accuracy: 0.8628\n","Epoch 31/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3336 - accuracy: 0.8644\n","Epoch 32/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3329 - accuracy: 0.8608\n","Epoch 33/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3327 - accuracy: 0.8629\n","Epoch 34/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8631\n","Epoch 35/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3326 - accuracy: 0.8642\n","Epoch 36/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3320 - accuracy: 0.8619\n","Epoch 37/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3313 - accuracy: 0.8633\n","Epoch 38/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8633\n","Epoch 39/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8632\n","Epoch 40/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3316 - accuracy: 0.8642\n","Epoch 41/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3308 - accuracy: 0.8656\n","Epoch 42/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3309 - accuracy: 0.8644\n","Epoch 43/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3309 - accuracy: 0.8633\n","Epoch 44/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8647\n","Epoch 45/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3304 - accuracy: 0.8626\n","Epoch 46/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3298 - accuracy: 0.8662\n","Epoch 47/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3298 - accuracy: 0.8639\n","Epoch 48/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3302 - accuracy: 0.8635\n","Epoch 49/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3298 - accuracy: 0.8635\n","Epoch 50/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3295 - accuracy: 0.8657\n","Epoch 51/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3295 - accuracy: 0.8656\n","Epoch 52/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3292 - accuracy: 0.8646\n","Epoch 53/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3285 - accuracy: 0.8647\n","Epoch 54/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3289 - accuracy: 0.8639\n","Epoch 55/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3289 - accuracy: 0.8656\n","Epoch 56/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8653\n","Epoch 57/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3272 - accuracy: 0.8639\n","Epoch 58/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3284 - accuracy: 0.8632\n","Epoch 59/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3280 - accuracy: 0.8639\n","Epoch 60/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3281 - accuracy: 0.8631\n","Epoch 61/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3277 - accuracy: 0.8644\n","Epoch 62/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3278 - accuracy: 0.8651\n","Epoch 63/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3274 - accuracy: 0.8642\n","Epoch 64/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3276 - accuracy: 0.8624\n","Epoch 65/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3279 - accuracy: 0.8642\n","Epoch 66/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3271 - accuracy: 0.8644\n","Epoch 67/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3269 - accuracy: 0.8632\n","Epoch 68/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3273 - accuracy: 0.8640\n","Epoch 69/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3273 - accuracy: 0.8643\n","Epoch 70/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3276 - accuracy: 0.8639\n","Epoch 71/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3272 - accuracy: 0.8642\n","Epoch 72/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3269 - accuracy: 0.8650\n","Epoch 73/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3273 - accuracy: 0.8647\n","Epoch 74/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3267 - accuracy: 0.8628\n","Epoch 75/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3268 - accuracy: 0.8621\n","Epoch 76/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3262 - accuracy: 0.8643\n","Epoch 77/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3271 - accuracy: 0.8621\n","Epoch 78/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3267 - accuracy: 0.8637\n","Epoch 79/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3267 - accuracy: 0.8661\n","Epoch 80/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3264 - accuracy: 0.8642\n","Epoch 81/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3271 - accuracy: 0.8639\n","Epoch 82/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3259 - accuracy: 0.8653\n","Epoch 83/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3266 - accuracy: 0.8644\n","Epoch 84/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3264 - accuracy: 0.8637\n","Epoch 85/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3268 - accuracy: 0.8639\n","Epoch 86/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3267 - accuracy: 0.8646\n","Epoch 87/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3263 - accuracy: 0.8657\n","Epoch 88/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3268 - accuracy: 0.8656\n","Epoch 89/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3266 - accuracy: 0.8651\n","Epoch 90/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3259 - accuracy: 0.8629\n","Epoch 91/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3268 - accuracy: 0.8647\n","Epoch 92/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3265 - accuracy: 0.8646\n","Epoch 93/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3258 - accuracy: 0.8646\n","Epoch 94/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3263 - accuracy: 0.8647\n","Epoch 95/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3259 - accuracy: 0.8653\n","Epoch 96/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3261 - accuracy: 0.8647\n","Epoch 97/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3261 - accuracy: 0.8650\n","Epoch 98/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3257 - accuracy: 0.8643\n","Epoch 99/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3252 - accuracy: 0.8660\n","Epoch 100/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3258 - accuracy: 0.8647\n","80/80 [==============================] - 0s 2ms/step\n","[CV] END ................................ score: (test=0.863) total time= 3.7min\n","Epoch 1/100\n","720/720 [==============================] - 3s 3ms/step - loss: 0.6113 - accuracy: 0.6875\n","Epoch 2/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4481 - accuracy: 0.8111\n","Epoch 3/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4126 - accuracy: 0.8231\n","Epoch 4/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3849 - accuracy: 0.8388\n","Epoch 5/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3676 - accuracy: 0.8492\n","Epoch 6/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3573 - accuracy: 0.8532\n","Epoch 7/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3515 - accuracy: 0.8557\n","Epoch 8/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3481 - accuracy: 0.8564\n","Epoch 9/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3448 - accuracy: 0.8593\n","Epoch 10/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3436 - accuracy: 0.8608\n","Epoch 11/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3419 - accuracy: 0.8608\n","Epoch 12/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3405 - accuracy: 0.8617\n","Epoch 13/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3403 - accuracy: 0.8611\n","Epoch 14/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3390 - accuracy: 0.8644\n","Epoch 15/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3387 - accuracy: 0.8607\n","Epoch 16/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3379 - accuracy: 0.8617\n","Epoch 17/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3370 - accuracy: 0.8633\n","Epoch 18/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3367 - accuracy: 0.8635\n","Epoch 19/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3354 - accuracy: 0.8644\n","Epoch 20/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3350 - accuracy: 0.8651\n","Epoch 21/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3350 - accuracy: 0.8626\n","Epoch 22/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3347 - accuracy: 0.8643\n","Epoch 23/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3342 - accuracy: 0.8631\n","Epoch 24/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3340 - accuracy: 0.8633\n","Epoch 25/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3339 - accuracy: 0.8642\n","Epoch 26/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3334 - accuracy: 0.8637\n","Epoch 27/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3341 - accuracy: 0.8625\n","Epoch 28/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3331 - accuracy: 0.8632\n","Epoch 29/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3329 - accuracy: 0.8649\n","Epoch 30/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3332 - accuracy: 0.8624\n","Epoch 31/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3327 - accuracy: 0.8621\n","Epoch 32/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3332 - accuracy: 0.8640\n","Epoch 33/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3323 - accuracy: 0.8646\n","Epoch 34/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8632\n","Epoch 35/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3321 - accuracy: 0.8637\n","Epoch 36/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3330 - accuracy: 0.8639\n","Epoch 37/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3325 - accuracy: 0.8640\n","Epoch 38/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8629\n","Epoch 39/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3326 - accuracy: 0.8637\n","Epoch 40/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3320 - accuracy: 0.8643\n","Epoch 41/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3322 - accuracy: 0.8622\n","Epoch 42/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8654\n","Epoch 43/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3320 - accuracy: 0.8651\n","Epoch 44/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3316 - accuracy: 0.8646\n","Epoch 45/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3322 - accuracy: 0.8633\n","Epoch 46/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3318 - accuracy: 0.8654\n","Epoch 47/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3313 - accuracy: 0.8637\n","Epoch 48/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3313 - accuracy: 0.8653\n","Epoch 49/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8651\n","Epoch 50/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3311 - accuracy: 0.8643\n","Epoch 51/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3317 - accuracy: 0.8642\n","Epoch 52/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3312 - accuracy: 0.8644\n","Epoch 53/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8649\n","Epoch 54/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8651\n","Epoch 55/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3313 - accuracy: 0.8649\n","Epoch 56/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3315 - accuracy: 0.8629\n","Epoch 57/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3310 - accuracy: 0.8651\n","Epoch 58/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3309 - accuracy: 0.8651\n","Epoch 59/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3310 - accuracy: 0.8635\n","Epoch 60/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8639\n","Epoch 61/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3309 - accuracy: 0.8651\n","Epoch 62/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3312 - accuracy: 0.8654\n","Epoch 63/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8640\n","Epoch 64/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3311 - accuracy: 0.8640\n","Epoch 65/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8653\n","Epoch 66/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8635\n","Epoch 67/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8635\n","Epoch 68/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3303 - accuracy: 0.8636\n","Epoch 69/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3311 - accuracy: 0.8653\n","Epoch 70/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3303 - accuracy: 0.8642\n","Epoch 71/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8622\n","Epoch 72/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3308 - accuracy: 0.8646\n","Epoch 73/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8626\n","Epoch 74/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8640\n","Epoch 75/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3305 - accuracy: 0.8640\n","Epoch 76/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3302 - accuracy: 0.8649\n","Epoch 77/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3303 - accuracy: 0.8628\n","Epoch 78/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8644\n","Epoch 79/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3304 - accuracy: 0.8633\n","Epoch 80/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3298 - accuracy: 0.8637\n","Epoch 81/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3302 - accuracy: 0.8635\n","Epoch 82/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8632\n","Epoch 83/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3307 - accuracy: 0.8636\n","Epoch 84/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8646\n","Epoch 85/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8617\n","Epoch 86/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3305 - accuracy: 0.8631\n","Epoch 87/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8629\n","Epoch 88/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8628\n","Epoch 89/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3299 - accuracy: 0.8650\n","Epoch 90/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8625\n","Epoch 91/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8658\n","Epoch 92/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3296 - accuracy: 0.8643\n","Epoch 93/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3299 - accuracy: 0.8642\n","Epoch 94/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3293 - accuracy: 0.8632\n","Epoch 95/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8614\n","Epoch 96/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3296 - accuracy: 0.8640\n","Epoch 97/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8651\n","Epoch 98/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3294 - accuracy: 0.8646\n","Epoch 99/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3299 - accuracy: 0.8636\n","Epoch 100/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3293 - accuracy: 0.8622\n","80/80 [==============================] - 0s 2ms/step\n","[CV] END ................................ score: (test=0.856) total time= 3.8min\n","Epoch 1/100\n","720/720 [==============================] - 3s 3ms/step - loss: 0.4860 - accuracy: 0.7882\n","Epoch 2/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4235 - accuracy: 0.8194\n","Epoch 3/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3979 - accuracy: 0.8342\n","Epoch 4/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3787 - accuracy: 0.8408\n","Epoch 5/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3658 - accuracy: 0.8482\n","Epoch 6/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3582 - accuracy: 0.8536\n","Epoch 7/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3526 - accuracy: 0.8553\n","Epoch 8/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3499 - accuracy: 0.8579\n","Epoch 9/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3473 - accuracy: 0.8574\n","Epoch 10/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3453 - accuracy: 0.8607\n","Epoch 11/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3443 - accuracy: 0.8601\n","Epoch 12/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3433 - accuracy: 0.8606\n","Epoch 13/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3422 - accuracy: 0.8632\n","Epoch 14/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3418 - accuracy: 0.8614\n","Epoch 15/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3412 - accuracy: 0.8629\n","Epoch 16/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3408 - accuracy: 0.8625\n","Epoch 17/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3401 - accuracy: 0.8628\n","Epoch 18/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3396 - accuracy: 0.8635\n","Epoch 19/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3393 - accuracy: 0.8626\n","Epoch 20/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3387 - accuracy: 0.8636\n","Epoch 21/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3385 - accuracy: 0.8654\n","Epoch 22/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3379 - accuracy: 0.8633\n","Epoch 23/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3369 - accuracy: 0.8642\n","Epoch 24/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3369 - accuracy: 0.8635\n","Epoch 25/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3367 - accuracy: 0.8646\n","Epoch 26/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3359 - accuracy: 0.8632\n","Epoch 27/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3360 - accuracy: 0.8653\n","Epoch 28/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3353 - accuracy: 0.8633\n","Epoch 29/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3356 - accuracy: 0.8650\n","Epoch 30/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3352 - accuracy: 0.8649\n","Epoch 31/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3345 - accuracy: 0.8656\n","Epoch 32/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3347 - accuracy: 0.8657\n","Epoch 33/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3345 - accuracy: 0.8654\n","Epoch 34/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3340 - accuracy: 0.8646\n","Epoch 35/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3342 - accuracy: 0.8642\n","Epoch 36/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3344 - accuracy: 0.8646\n","Epoch 37/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3334 - accuracy: 0.8647\n","Epoch 38/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3333 - accuracy: 0.8654\n","Epoch 39/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3337 - accuracy: 0.8667\n","Epoch 40/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3337 - accuracy: 0.8665\n","Epoch 41/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3332 - accuracy: 0.8665\n","Epoch 42/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3327 - accuracy: 0.8667\n","Epoch 43/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3332 - accuracy: 0.8653\n","Epoch 44/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3329 - accuracy: 0.8667\n","Epoch 45/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3333 - accuracy: 0.8668\n","Epoch 46/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3331 - accuracy: 0.8667\n","Epoch 47/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8681\n","Epoch 48/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3320 - accuracy: 0.8642\n","Epoch 49/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3325 - accuracy: 0.8658\n","Epoch 50/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3320 - accuracy: 0.8667\n","Epoch 51/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3324 - accuracy: 0.8656\n","Epoch 52/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3323 - accuracy: 0.8665\n","Epoch 53/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3327 - accuracy: 0.8649\n","Epoch 54/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3327 - accuracy: 0.8662\n","Epoch 55/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8654\n","Epoch 56/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3321 - accuracy: 0.8643\n","Epoch 57/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8672\n","Epoch 58/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3313 - accuracy: 0.8668\n","Epoch 59/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8667\n","Epoch 60/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3315 - accuracy: 0.8672\n","Epoch 61/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3320 - accuracy: 0.8644\n","Epoch 62/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8675\n","Epoch 63/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3318 - accuracy: 0.8651\n","Epoch 64/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3318 - accuracy: 0.8656\n","Epoch 65/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3316 - accuracy: 0.8650\n","Epoch 66/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3307 - accuracy: 0.8649\n","Epoch 67/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3312 - accuracy: 0.8656\n","Epoch 68/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3308 - accuracy: 0.8643\n","Epoch 69/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8642\n","Epoch 70/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3310 - accuracy: 0.8662\n","Epoch 71/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8646\n","Epoch 72/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8649\n","Epoch 73/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3308 - accuracy: 0.8661\n","Epoch 74/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8662\n","Epoch 75/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3311 - accuracy: 0.8646\n","Epoch 76/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3305 - accuracy: 0.8646\n","Epoch 77/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8674\n","Epoch 78/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3307 - accuracy: 0.8657\n","Epoch 79/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3303 - accuracy: 0.8649\n","Epoch 80/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3307 - accuracy: 0.8632\n","Epoch 81/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8651\n","Epoch 82/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3303 - accuracy: 0.8633\n","Epoch 83/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8649\n","Epoch 84/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3305 - accuracy: 0.8657\n","Epoch 85/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8647\n","Epoch 86/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3305 - accuracy: 0.8653\n","Epoch 87/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3305 - accuracy: 0.8657\n","Epoch 88/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3305 - accuracy: 0.8646\n","Epoch 89/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8647\n","Epoch 90/100\n","720/720 [==============================] - 3s 3ms/step - loss: 0.3301 - accuracy: 0.8658\n","Epoch 91/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8669\n","Epoch 92/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3304 - accuracy: 0.8653\n","Epoch 93/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3298 - accuracy: 0.8661\n","Epoch 94/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3303 - accuracy: 0.8643\n","Epoch 95/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3296 - accuracy: 0.8646\n","Epoch 96/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3302 - accuracy: 0.8650\n","Epoch 97/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8643\n","Epoch 98/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3302 - accuracy: 0.8640\n","Epoch 99/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.8657\n","Epoch 100/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3302 - accuracy: 0.8661\n","80/80 [==============================] - 0s 2ms/step\n","[CV] END ................................ score: (test=0.850) total time= 4.4min\n","Epoch 1/100\n","720/720 [==============================] - 3s 3ms/step - loss: 0.5287 - accuracy: 0.7843\n","Epoch 2/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4498 - accuracy: 0.7960\n","Epoch 3/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4328 - accuracy: 0.7960\n","Epoch 4/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4244 - accuracy: 0.8001\n","Epoch 5/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4181 - accuracy: 0.8231\n","Epoch 6/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4135 - accuracy: 0.8254\n","Epoch 7/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4097 - accuracy: 0.8279\n","Epoch 8/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4063 - accuracy: 0.8325\n","Epoch 9/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4033 - accuracy: 0.8336\n","Epoch 10/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.4006 - accuracy: 0.8381\n","Epoch 11/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3975 - accuracy: 0.8374\n","Epoch 12/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3938 - accuracy: 0.8386\n","Epoch 13/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3885 - accuracy: 0.8397\n","Epoch 14/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3773 - accuracy: 0.8451\n","Epoch 15/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3633 - accuracy: 0.8524\n","Epoch 16/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3529 - accuracy: 0.8576\n","Epoch 17/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3467 - accuracy: 0.8603\n","Epoch 18/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3438 - accuracy: 0.8612\n","Epoch 19/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3416 - accuracy: 0.8624\n","Epoch 20/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3403 - accuracy: 0.8610\n","Epoch 21/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3397 - accuracy: 0.8624\n","Epoch 22/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3385 - accuracy: 0.8640\n","Epoch 23/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3385 - accuracy: 0.8607\n","Epoch 24/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3378 - accuracy: 0.8621\n","Epoch 25/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3370 - accuracy: 0.8625\n","Epoch 26/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3373 - accuracy: 0.8636\n","Epoch 27/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3371 - accuracy: 0.8622\n","Epoch 28/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3362 - accuracy: 0.8628\n","Epoch 29/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3364 - accuracy: 0.8633\n","Epoch 30/100\n","720/720 [==============================] - 4s 5ms/step - loss: 0.3364 - accuracy: 0.8632\n","Epoch 31/100\n","720/720 [==============================] - 4s 5ms/step - loss: 0.3362 - accuracy: 0.8628\n","Epoch 32/100\n","720/720 [==============================] - 4s 5ms/step - loss: 0.3366 - accuracy: 0.8633\n","Epoch 33/100\n","720/720 [==============================] - 3s 4ms/step - loss: 0.3358 - accuracy: 0.8631\n","Epoch 34/100\n","720/720 [==============================] - 3s 5ms/step - loss: 0.3354 - accuracy: 0.8633\n","Epoch 35/100\n","720/720 [==============================] - 4s 6ms/step - loss: 0.3360 - accuracy: 0.8643\n","Epoch 36/100\n","720/720 [==============================] - 4s 5ms/step - loss: 0.3358 - accuracy: 0.8633\n","Epoch 37/100\n","720/720 [==============================] - 2s 3ms/step - loss: 0.3353 - accuracy: 0.8632\n","Epoch 38/100\n"," 40/720 [>.............................] - ETA: 2s - loss: 0.3127 - accuracy: 0.8725"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-1535050d7d92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1454\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         self._fit(\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m         )\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m         )\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["#Hyperparameter tuning of Neural Network\n","from scikeras.wrappers import KerasClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","def buildNN():\n","    model = tf.keras.models.Sequential()\n","    model.add(tf.keras.layers.Dense(units=6, input_shape=[11], activation='relu'))\n","    model.add(tf.keras.layers.Dropout(0.1))\n","    model.add(tf.keras.layers.Dense(units=6, activation='relu'))\n","    model.add(tf.keras.layers.Dropout(0.1))\n","    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","classifier = KerasClassifier(model = buildNN)\n","parameters = {'batch_size':[25,32], 'epochs':[10,15], 'optimizer':['adam','rmsprop']}\n","grid_search = GridSearchCV(estimator =classifier, param_grid=parameters, scoring='accuracy', cv=10)\n","grid_search = grid_search.fit(X_train, y_train)\n","best_param = grid_search.best_params_\n","best_acc=grid_search.best_score_\n","\n","print(best_param)\n","print(best_acc)"],"metadata":{"id":"Es6-LuVrebfW"},"execution_count":null,"outputs":[]}]}