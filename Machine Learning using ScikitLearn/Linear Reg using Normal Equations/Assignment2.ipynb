{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cheap-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-charm",
   "metadata": {},
   "source": [
    "Q1) Load the dataset into a pandas dataframe and display the first 5 lines of the dataset along with the column headings. Note that the text file does not have the headers, which means you will have to add them to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sensitive-library",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0  0.02731  0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0     17.8   \n",
       "1  0.02729  0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0     17.8   \n",
       "2  0.03237  0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0     18.7   \n",
       "3  0.06905  0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0     18.7   \n",
       "4  0.02985  0.0   2.18     0  0.458  6.430  58.7  6.0622    3  222.0     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   9.14  21.6  \n",
       "1  392.83   4.03  34.7  \n",
       "2  394.63   2.94  33.4  \n",
       "3  396.90   5.33  36.2  \n",
       "4  394.12   5.21  28.7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading dataset from the data.txt file into pandas dataframe.\n",
    "housing_df = pd.read_csv('data.txt',delimiter='\\s+')\n",
    "housing_df.columns = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-casting",
   "metadata": {},
   "source": [
    "Q2) Split the dataset into training (70%) and testing set (30%). Normalize the data using standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gentle-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading target variable and input variables into different data frames\n",
    "X = housing_df.iloc[:,:-1].values\n",
    "y = housing_df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "empty-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and y into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vocational-collective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0    22.8\n",
       "1    31.2\n",
       "2    14.4\n",
       "3    17.4\n",
       "4    20.8\n",
       "..    ...\n",
       "147  19.1\n",
       "148  21.4\n",
       "149  17.3\n",
       "150  43.1\n",
       "151  15.6\n",
       "\n",
       "[152 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checing X_train, X_test, y_train, y_test\n",
    "pd.DataFrame(X_train)\n",
    "pd.DataFrame(X_test)\n",
    "pd.DataFrame(y_train)\n",
    "pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mature-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing data using Standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "st_sc_X = StandardScaler()\n",
    "X_train = st_sc_X.fit_transform(X_train)\n",
    "X_test = st_sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-integration",
   "metadata": {},
   "source": [
    "Q3) Model 1: Using scikit learn, build a Linear Regression model with all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "palestinian-parish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lrObj = LinearRegression()\n",
    "lrObj.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-communication",
   "metadata": {},
   "source": [
    "Q4) What are the weight parameters (including the intercept) you get for Model 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "surgical-patrol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for different input variables are: \n",
      "[-0.87475313  1.65119298  0.16320752  0.83976231 -2.82242031  1.98885935\n",
      " -0.00819484 -3.76457001  2.97801011 -2.38451308 -1.75116199  0.35444245\n",
      " -4.15292395]\n",
      "\n",
      "Intercept is:\n",
      "22.39320113314451\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights for different input variables are: \")\n",
    "print(lrObj.coef_)\n",
    "\n",
    "print()\n",
    "print(\"Intercept is:\")\n",
    "print(lrObj.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-donna",
   "metadata": {},
   "source": [
    "Q5) Use Model 1 to make a prediction on the test set. Calculate mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "flush-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Values from test data\n",
      "[22.8 31.2 14.4 17.4 20.8 18.4 23.9 13.2 23.  22.  23.7 17.5 22.  22.\n",
      " 21.6 27.9 13.9 37.6 42.3 17.8 17.8 14.6 16.2 24.6 19.4  8.3 18.9 17.2\n",
      " 48.8 11.5 18.6 24.3 22.6 12.6 17.1 24.5 14.9 28.7 13.4 19.1 19.8 21.1\n",
      " 44.8 13.3  5.   8.4 50.  21.8 50.  19.3 29.8 23.7 22.9 22.3 15.1 25.\n",
      " 50.  19.4 20.2 29.  16.7 22.5 23.9 14.5 25.  39.8 48.3 23.9 28.6 25.\n",
      " 22.2 10.5 21.9 12.7 19.8 19.1 14.6 20.1 27.  27.9 14.3 20.4 37.  13.4\n",
      " 24.1 29.  19.7 23.  18.3 17.4  8.8 36.  13.6 27.1 10.9 21.7 22.4 25.\n",
      " 50.  22.8 10.2 15.4 24.7 19.6 25.  20.3 11.7 50.  50.  18.6 20.7 22.6\n",
      " 11.  28.2 30.1 31.1 18.7 18.2 26.6 43.5 22.6 14.9 25.3 19.9 28.5 21.2\n",
      " 21.7 20.6 23.6 23.9 16.6 21.  20.6 14.1 24.8 28.4 15.6 12.7 36.2 10.4\n",
      " 22.6 14.  20.4 23.3 37.3 20.5 23.1 19.1 21.4 17.3 43.1 15.6]\n",
      "\n",
      "Predicted values of target variable\n",
      "[28.28462326 28.46747019  8.61857398 17.90847    18.33305008 15.76308795\n",
      " 25.52414714  9.19067917 29.43242231 27.4027452  26.96758001 15.83854232\n",
      " 22.27875974 21.56479422 25.4312481  20.9169054  16.92283603 36.19028473\n",
      " 36.83068061  7.825325   17.1866712   6.65668248 20.61181852 24.52383046\n",
      " 26.99137051 11.46112523 24.36625238 14.2018283  38.24463135 14.24702564\n",
      " 16.96399412 20.01111381 23.06102419 17.20836796 20.33855261 20.64474628\n",
      " 17.01071147 24.97457315 17.23350679 19.46166164 21.02505201 20.59817322\n",
      " 36.817815   16.28591414  6.29836611 14.9027928  39.5362182  21.61247194\n",
      " 35.07359129 20.63628174 24.88814275 27.50220378 22.20156916 25.82705941\n",
      " 17.05894852 22.01299244 33.17177678 23.32962136 17.56108857 31.78035551\n",
      " 19.17976816 22.39397592 27.38223247 19.65872832 24.65661173 33.65653492\n",
      " 35.44902393 27.81394582 27.58822136 25.38664867 19.14605222  6.68270935\n",
      " 16.61529817 11.54401673 22.75971615 17.19504837 19.07200243 21.06449807\n",
      " 32.74437878 33.70236583 14.18876151 20.52907589 30.28633811 13.26061021\n",
      " 20.14819745 31.77843112 14.08573693 23.57470417 19.07761356 15.87849646\n",
      "  4.59354586 34.81864705 13.09528408 18.13280721 15.79972168 20.16386752\n",
      " 23.44323903 30.12099376 37.80171905 25.76291877 18.79720647 16.87006493\n",
      " 24.51772919 21.65562089 28.13110482 22.88525273 17.34809774 35.16184266\n",
      " 34.80939253 21.68638064 26.90987129 26.85075252 15.14496259 33.39142642\n",
      " 33.76827234 32.46543575 21.72160315 18.97209521 27.54866692 37.88558532\n",
      " 23.74141274 15.88065283 25.28452579 18.09650647 35.13537405 21.23923139\n",
      " 24.1464975  22.79542236 28.87024536 27.30412681 17.55171078 20.94735481\n",
      " 27.80925234 19.62574354 26.70896634 31.59468768  9.88694228 13.95780606\n",
      " 28.25476909 13.55925228 18.31495711 13.06448737 21.25799834 28.37620221\n",
      " 35.8119752  19.72644243 24.88630884 17.15595664 24.99157517 16.40640249\n",
      " 35.25693216 15.61600091]\n",
      "\n",
      "Mean Squared Error: 23.979929149691568\n"
     ]
    }
   ],
   "source": [
    "#Predicting on test dataset\n",
    "y_pred = lrObj.predict(X_test)\n",
    "\n",
    "print(\"Actual Values from test data\")\n",
    "print(y_test)\n",
    "\n",
    "print(\"\\nPredicted values of target variable\")\n",
    "print(y_pred)\n",
    "\n",
    "MSE = np.square(np.subtract(y_test,y_pred)).mean()\n",
    "print(\"\\nMean Squared Error: \"+str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "favorite-james",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-yield",
   "metadata": {},
   "source": [
    "Q6) Model 2: Build a linear regression model with all the variables using Normal Equations method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lasting-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a copy of Input variables and predictor variable\n",
    "X_ne = X\n",
    "y_ne = y\n",
    "\n",
    "y_ne = pd.DataFrame(y_ne)\n",
    "X_ne = pd.DataFrame(X_ne)\n",
    "\n",
    "#Adding a column with 1's for intercept\n",
    "X0 = np.ones(505)\n",
    "X_ne.insert(0,'X0',X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "demographic-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset into training and test\n",
    "X_ne_train, X_ne_test, y_ne_train, y_ne_test = train_test_split(X_ne, y_ne, test_size=0.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "closing-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating weights as per equation w = (X.T dot X)inv dot X.T dot y\n",
    "term1 = np.linalg.inv(X_ne_train.T.dot(X_ne_train))\n",
    "term2 = np.dot(X_ne_train.T,y_ne_train)\n",
    "w_ne = term1.dot(term2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-fleet",
   "metadata": {},
   "source": [
    "Q7) What are the weight parameters you get for Model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beneficial-spouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for different input variables are: \n",
      "[[-1.00187309e-01]\n",
      " [ 4.53084230e-02]\n",
      " [ 5.59255159e-02]\n",
      " [ 2.79972642e+00]\n",
      " [-1.89498465e+01]\n",
      " [ 3.75882434e+00]\n",
      " [ 1.78635670e-02]\n",
      " [-1.25606171e+00]\n",
      " [ 2.64216739e-01]\n",
      " [-9.80224513e-03]\n",
      " [-1.06234424e+00]\n",
      " [ 7.67567172e-03]\n",
      " [-5.77719397e-01]]\n",
      "\n",
      "Intercept is:\n",
      "[37.68227759]\n"
     ]
    }
   ],
   "source": [
    "#Printing weights for all input variables\n",
    "print(\"Weights for different input variables are: \")\n",
    "print(w_ne[1:])\n",
    "\n",
    "print()\n",
    "#Printing intercept\n",
    "print(\"Intercept is:\")\n",
    "print(w_ne[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-underground",
   "metadata": {},
   "source": [
    "Q8) Use Model 2 to make a prediction on the test set. Calculate mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "opponent-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the output variable using calculated weights\n",
    "ye_ne_pred = np.dot(X_ne_test,w_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "organic-chest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0    21.381584\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Calculating MSE for normal equations linear regression model\n",
    "MSE_ne = np.square(np.subtract(y_ne_test,ye_ne_pred)).mean()\n",
    "print(\"Mean Squared Error: \"+str(MSE_ne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-smile",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
