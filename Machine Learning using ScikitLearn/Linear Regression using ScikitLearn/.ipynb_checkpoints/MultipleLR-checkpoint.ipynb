{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 2300 0 1.1]\n",
      " [0.0 1.0 0.0 2100 1 1.3]\n",
      " [1.0 0.0 0.0 2104 2 1.5]\n",
      " [0.0 0.0 1.0 1200 1 2.0]\n",
      " [0.0 1.0 0.0 1254 2 2.2]\n",
      " [0.0 0.0 1.0 1236 1 2.9]\n",
      " [1.0 0.0 0.0 1452 2 3.0]\n",
      " [0.0 1.0 0.0 1789 1 3.2]\n",
      " [0.0 0.0 1.0 1645 1 3.2]\n",
      " [0.0 0.0 1.0 1258 0 3.7]\n",
      " [0.0 1.0 0.0 1478 3 3.9]\n",
      " [1.0 0.0 0.0 1257 2 4.0]\n",
      " [1.0 0.0 0.0 1596 1 4.0]\n",
      " [0.0 1.0 0.0 1256 2 4.1]\n",
      " [0.0 0.0 1.0 1489 3 4.5]\n",
      " [1.0 0.0 0.0 1236 3 4.9]\n",
      " [0.0 1.0 0.0 2311 2 5.1]\n",
      " [0.0 0.0 1.0 2245 3 5.3]\n",
      " [1.0 0.0 0.0 2365 1 5.9]\n",
      " [1.0 0.0 0.0 1500 3 6.0]\n",
      " [0.0 1.0 0.0 1456 2 6.8]\n",
      " [0.0 1.0 0.0 1760 1 7.1]\n",
      " [0.0 0.0 1.0 2400 4 7.9]\n",
      " [1.0 0.0 0.0 2148 3 8.2]\n",
      " [0.0 0.0 1.0 1450 2 8.7]\n",
      " [0.0 0.0 1.0 1000 4 9.0]\n",
      " [0.0 1.0 0.0 1540 3 9.5]\n",
      " [1.0 0.0 0.0 1500 2 9.6]\n",
      " [0.0 1.0 0.0 3000 4 10.3]\n",
      " [0.0 0.0 1.0 2100 3 10.5]]\n"
     ]
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Loading the dataset\n",
    "dataset = pd.read_csv('employee.csv')\n",
    "\n",
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,4].values\n",
    "\n",
    "#Dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "onehotencoder = make_column_transformer((OneHotEncoder(), [0]), remainder='passthrough')\n",
    "X = onehotencoder.fit_transform(X)\n",
    "\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 0.000e+00 0.000e+00 2.300e+03 0.000e+00 1.100e+00]\n",
      " [1.000e+00 1.000e+00 0.000e+00 2.100e+03 1.000e+00 1.300e+00]\n",
      " [1.000e+00 0.000e+00 0.000e+00 2.104e+03 2.000e+00 1.500e+00]\n",
      " [1.000e+00 0.000e+00 1.000e+00 1.200e+03 1.000e+00 2.000e+00]\n",
      " [1.000e+00 1.000e+00 0.000e+00 1.254e+03 2.000e+00 2.200e+00]\n",
      " [1.000e+00 0.000e+00 1.000e+00 1.236e+03 1.000e+00 2.900e+00]\n",
      " [1.000e+00 0.000e+00 0.000e+00 1.452e+03 2.000e+00 3.000e+00]\n",
      " [1.000e+00 1.000e+00 0.000e+00 1.789e+03 1.000e+00 3.200e+00]\n",
      " [1.000e+00 0.000e+00 1.000e+00 1.645e+03 1.000e+00 3.200e+00]\n",
      " [1.000e+00 0.000e+00 1.000e+00 1.258e+03 0.000e+00 3.700e+00]\n",
      " [1.000e+00 1.000e+00 0.000e+00 1.478e+03 3.000e+00 3.900e+00]\n",
      " [1.000e+00 0.000e+00 0.000e+00 1.257e+03 2.000e+00 4.000e+00]\n",
      " [1.000e+00 0.000e+00 0.000e+00 1.596e+03 1.000e+00 4.000e+00]\n",
      " [1.000e+00 1.000e+00 0.000e+00 1.256e+03 2.000e+00 4.100e+00]\n",
      " [1.000e+00 0.000e+00 1.000e+00 1.489e+03 3.000e+00 4.500e+00]\n",
      " [1.000e+00 0.000e+00 0.000e+00 1.236e+03 3.000e+00 4.900e+00]\n",
      " [1.000e+00 1.000e+00 0.000e+00 2.311e+03 2.000e+00 5.100e+00]\n",
      " [1.000e+00 0.000e+00 1.000e+00 2.245e+03 3.000e+00 5.300e+00]\n",
      " [1.000e+00 0.000e+00 0.000e+00 2.365e+03 1.000e+00 5.900e+00]\n",
      " [1.000e+00 0.000e+00 0.000e+00 1.500e+03 3.000e+00 6.000e+00]\n",
      " [1.000e+00 1.000e+00 0.000e+00 1.456e+03 2.000e+00 6.800e+00]\n",
      " [1.000e+00 1.000e+00 0.000e+00 1.760e+03 1.000e+00 7.100e+00]\n",
      " [1.000e+00 0.000e+00 1.000e+00 2.400e+03 4.000e+00 7.900e+00]\n",
      " [1.000e+00 0.000e+00 0.000e+00 2.148e+03 3.000e+00 8.200e+00]\n",
      " [1.000e+00 0.000e+00 1.000e+00 1.450e+03 2.000e+00 8.700e+00]\n",
      " [1.000e+00 0.000e+00 1.000e+00 1.000e+03 4.000e+00 9.000e+00]\n",
      " [1.000e+00 1.000e+00 0.000e+00 1.540e+03 3.000e+00 9.500e+00]\n",
      " [1.000e+00 0.000e+00 0.000e+00 1.500e+03 2.000e+00 9.600e+00]\n",
      " [1.000e+00 1.000e+00 0.000e+00 3.000e+03 4.000e+00 1.030e+01]\n",
      " [1.000e+00 0.000e+00 1.000e+00 2.100e+03 3.000e+00 1.050e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Removing the extra dummy variable\n",
    "X = X[:, 1:]\n",
    "\n",
    "#Splitting the data into Training Set and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "                      \n",
    "\n",
    "#Fitting Multiple Linear Regression to Training Set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "mlrObj = LinearRegression()\n",
    "mlrObj.fit(X_train,y_train)\n",
    "\n",
    "#Predicting on the Test Set\n",
    "y_pred = mlrObj.predict(X_test)\n",
    "\n",
    "#Backward Elimination\n",
    "import statsmodels.api as sm\n",
    "X = np.append(arr=np.ones((30,1)).astype(int), values=X, axis=1)\n",
    "\n",
    "# Convert to a float64\n",
    "X = X.astype('float64')  # Without this, OLS function errors out\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sig = X[:,[0,1,2,3,4,5]]\n",
    "obj_OLS = sm.OLS(endog = y, exog = X_sig).fit()\n",
    "obj_OLS.summary()\n",
    "\n",
    "X_sig = X[:,[0,1,3,4,5]]\n",
    "\n",
    "obj_OLS = sm.OLS(endog = y, exog = X_sig).fit()\n",
    "obj_OLS.summary()\n",
    "\n",
    "X_sig = X[:,[0,1,3,5]]\n",
    "\n",
    "obj_OLS = sm.OLS(endog = y, exog = X_sig).fit()\n",
    "obj_OLS.summary()\n",
    "\n",
    "X_sig = X[:,[0,3,5]]\n",
    "\n",
    "obj_OLS = sm.OLS(endog = y, exog = X_sig).fit()\n",
    "obj_OLS.summary()\n",
    "\n",
    "X_sig = X[:,[0,5]]\n",
    "\n",
    "obj_OLS = sm.OLS(endog = y, exog = X_sig).fit()\n",
    "obj_OLS.summary()\n",
    "\n",
    "#Splitting the data into Training Set and Test Set\n",
    "X_sig_train, X_sig_test, y_sig_train, y_sig_test = train_test_split(X_sig, y, test_size=0.2,random_state=0)\n",
    "mlrObj_sig = LinearRegression()\n",
    "mlrObj_sig.fit(X_sig_train, y_sig_train)\n",
    "\n",
    "y_sig_pred = mlrObj_sig.predict(X_sig_test)\n",
    "\n",
    "#Normalizing the features\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc_X = StandardScaler()\n",
    "#X_train = sc_X.fit_transform(X_train)\n",
    "#X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.24.1.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
